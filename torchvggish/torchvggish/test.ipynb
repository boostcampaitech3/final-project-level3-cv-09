{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvggish import vggish, vggish_input, vggish_params, mel_features\n",
    "import resampy\n",
    "import torch\n",
    "# import tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wavfile_to_examples() 테스트 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import soundfile as sf\n",
    "# import numpy as np\n",
    "\n",
    "# wav_file = '/opt/ml/pd/torchvggish/testset.wav'\n",
    "# wav_data, sr = sf.read(wav_file, dtype='int16')\n",
    "# assert wav_data.dtype == np.int16, 'Bad sample type: %r' % wav_data.dtype\n",
    "# samples = wav_data / 32768.0  # Convert to [-1.0, +1.0]\n",
    "# # return waveform_to_examples(samples, sr, return_tensor)\n",
    "# data = samples\n",
    "# sample_rate = sr\n",
    "# print(data.shape)\n",
    "# print(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if len(data.shape) > 1:\n",
    "#     data = np.mean(data, axis=1)\n",
    "# print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Resample to the rate assumed by VGGish.\n",
    "# if sample_rate != vggish_params.SAMPLE_RATE:\n",
    "#     data = resampy.resample(data, sample_rate, vggish_params.SAMPLE_RATE)\n",
    "# print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Compute log mel spectrogram features.\n",
    "# log_mel = mel_features.log_mel_spectrogram(\n",
    "#     data,\n",
    "#     audio_sample_rate=vggish_params.SAMPLE_RATE,\n",
    "#     log_offset=vggish_params.LOG_OFFSET,\n",
    "#     window_length_secs=vggish_params.STFT_WINDOW_LENGTH_SECONDS,\n",
    "#     hop_length_secs=vggish_params.STFT_HOP_LENGTH_SECONDS,\n",
    "#     num_mel_bins=vggish_params.NUM_MEL_BINS,\n",
    "#     lower_edge_hertz=vggish_params.MEL_MIN_HZ,\n",
    "#     upper_edge_hertz=vggish_params.MEL_MAX_HZ)\n",
    "# print(log_mel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Frame features into examples.\n",
    "# features_sample_rate = 1.0 / vggish_params.STFT_HOP_LENGTH_SECONDS\n",
    "# # print(features_sample_rate)\n",
    "# example_window_length = int(round(\n",
    "#     vggish_params.EXAMPLE_WINDOW_SECONDS * features_sample_rate))\n",
    "# # print(example_window_length)\n",
    "# example_hop_length = int(round(\n",
    "#     vggish_params.EXAMPLE_HOP_SECONDS * features_sample_rate))\n",
    "# # print(example_hop_length)\n",
    "# print(log_mel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# log_mel_examples = mel_features.frame(\n",
    "#     log_mel,\n",
    "#     window_length=example_window_length,\n",
    "#     hop_length=example_hop_length)\n",
    "# # print(log_mel_examples.shape)\n",
    "# #   if return_tensor:\n",
    "# #       log_mel_examples = torch.tensor(\n",
    "# #           log_mel_examples, requires_grad=True)[:, None, :, :].float()\n",
    "\n",
    "# #   return log_mel_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_samples = log_mel.shape[0]\n",
    "# # print(num_samples)\n",
    "# num_frames = 1 + int(np.floor((num_samples - 96) / 96))\n",
    "# print(num_frames)\n",
    "# # shape = (num_frames, 96) + data.shape[1:]\n",
    "# # strides = (data.strides[0] * 96,) + data.strides\n",
    "# # return np.lib.stride_tricks.as_strided(data, shape=shape, strides=strides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature extraction 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise model and download weights\n",
    "model_urls = {\n",
    "    'vggish': 'https://github.com/harritaylor/torchvggish/'\n",
    "    'releases/download/v0.1/vggish-10086976.pth',\n",
    "    'pca': 'https://github.com/harritaylor/torchvggish/'\n",
    "    'releases/download/v0.1/vggish_pca_params-970ea276.pth'\n",
    "    }\n",
    "embedding_model = vggish.VGGish(urls=model_urls)\n",
    "# embedding_model.load_state_dict(torch.load(\"/opt/ml/torchvggish/torchvggish/vggish.pth\"))\n",
    "embedding_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example = vggish_input.wavfile_to_examples(\"/opt/ml/torchvggish/testset.wav\")\n",
    "# print(example.shape)\n",
    "# print(type(example))\n",
    "# example\n",
    "# embedding_model.eval()\n",
    "# # examples = example.numpy()\n",
    "embeddings = embedding_model.forward(\"/opt/ml/pd/torchvggish/testset.wav\")#(example.detach().numpy())\n",
    "print(embeddings.shape)\n",
    "print(type(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python ('level3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
