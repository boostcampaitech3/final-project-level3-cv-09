{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('/opt/ml/input/data/test_video.mp4')\n",
    "FPS = cap.get(5) \n",
    "frame = cap.get(7)\n",
    "count = 1\n",
    "\n",
    "for i in range(1, int(frame)):\n",
    "    success, img = cap.read()\n",
    "    \n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    if i % (1.25) < 1:\n",
    "        cv2.imwrite(f\"/opt/ml/input/data/test_video/test_video\"+'-'+str(count).zfill(6)+'.jpg', img)\n",
    "        count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import videotransforms\n",
    "\n",
    "import numpy as np\n",
    "from pytorch_i3d import InceptionI3d\n",
    "from charades_dataset_full import Charades as Dataset\n",
    "from utils import createDirectory\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([])\n",
    "first_transforms = transforms.Compose([videotransforms.FirstCrop(224)])\n",
    "second_transforms = transforms.Compose([videotransforms.SecondCrop(224)])\n",
    "third_transforms = transforms.Compose([videotransforms.ThirdCrop(224)])\n",
    "fourth_transforms = transforms.Compose([videotransforms.FourthCrop(224)])\n",
    "center_transforms = transforms.Compose([videotransforms.CenterCrop(224)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Saved : /opt/ml/input/data/test_video_1.npy\n",
      "Success Saved : /opt/ml/input/data/test_video_2.npy\n",
      "Success Saved : /opt/ml/input/data/test_video_3.npy\n",
      "Success Saved : /opt/ml/input/data/test_video_4.npy\n",
      "Success Saved : /opt/ml/input/data/test_video_5.npy\n"
     ]
    }
   ],
   "source": [
    "split = '/opt/ml/input/data/test.json'\n",
    "root = '/opt/ml/input/data'\n",
    "mode = 'rgb'\n",
    "batch_size = 1\n",
    "save_dir = '/opt/ml/input/data'\n",
    "load_model = '/opt/ml/input/code/pytorch-i3d/models/rgb_charades.pt'\n",
    "\n",
    "first_dataset = Dataset(split, 'testing', root, mode, first_transforms, num=-1, save_dir=save_dir)\n",
    "first_dataloader = torch.utils.data.DataLoader(first_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "second_dataset = Dataset(split, 'testing', root, mode, second_transforms, num=-1, save_dir=save_dir)\n",
    "second_dataloader = torch.utils.data.DataLoader(second_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "third_dataset = Dataset(split, 'testing', root, mode, third_transforms, num=-1, save_dir=save_dir)\n",
    "third_dataloader = torch.utils.data.DataLoader(third_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "fourth_dataset = Dataset(split, 'testing', root, mode, fourth_transforms, num=-1, save_dir=save_dir)\n",
    "fourth_dataloader = torch.utils.data.DataLoader(fourth_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "center_dataset = Dataset(split, 'testing', root, mode, center_transforms, num=-1, save_dir=save_dir)\n",
    "center_dataloader = torch.utils.data.DataLoader(center_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "\n",
    "dataloaders = {\n",
    "               '1': first_dataloader,\n",
    "               '2': second_dataloader,\n",
    "               '3': third_dataloader,\n",
    "               '4': fourth_dataloader,\n",
    "               '5': center_dataloader,\n",
    "                }\n",
    "\n",
    "datasets = {\n",
    "            '1': first_dataset,\n",
    "            '2': second_dataset,\n",
    "            '3': third_dataset,\n",
    "            '4': fourth_dataset,\n",
    "            '5': center_dataset,\n",
    "            }  \n",
    "\n",
    "i3d = InceptionI3d(400, in_channels=3)\n",
    "i3d.replace_logits(157)\n",
    "i3d.load_state_dict(torch.load(load_model))\n",
    "i3d.cuda()\n",
    "i3d.train(False)  # Set model to evaluate mode\n",
    "        \n",
    "# Iterate over data.\n",
    "for phase in ['1', '2', '3', '4', '5']:\n",
    "    for data in dataloaders[phase]:\n",
    "        # get the inputs\n",
    "        inputs, labels, name = data\n",
    "        b,c,t,h,w = inputs.shape\n",
    "        features = []\n",
    "        for start in range(1, t-16, 16):\n",
    "            end = start + 16 \n",
    "            ip = Variable(torch.from_numpy(inputs.numpy()[:,:,start:end]).cuda())\n",
    "            features.append(i3d.extract_features(ip).squeeze(0).permute(1,2,3,0).data.cpu().numpy())\n",
    "        # np.save(os.path.join(save_dir, name[0]+f\"_{phase}\"), np.concatenate(features, axis=0))\n",
    "        np.save(os.path.join(save_dir, name[0]+f\"_{phase}\"), np.concatenate(features, axis=0).reshape(-1, 1024))\n",
    "        print(f\"Success Saved : {os.path.join(save_dir, name[0]+'_'+phase)}.npy\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_crop : (510, 1024)\n",
      "second_crop : (510, 1024)\n",
      "third_crop : (510, 1024)\n",
      "fourth_crop : (510, 1024)\n",
      "center_crop : (510, 1024)\n"
     ]
    }
   ],
   "source": [
    "first_data = np.load('/opt/ml/input/data/test_video_1.npy')\n",
    "second_data = np.load('/opt/ml/input/data/test_video_2.npy')\n",
    "third_data = np.load('/opt/ml/input/data/test_video_3.npy')\n",
    "fourth_data = np.load('/opt/ml/input/data/test_video_4.npy')\n",
    "center_data = np.load('/opt/ml/input/data/test_video_5.npy')\n",
    "\n",
    "print('first_crop :', first_data.shape)\n",
    "print('second_crop :', second_data.shape)\n",
    "print('third_crop :', third_data.shape)\n",
    "print('fourth_crop :', fourth_data.shape)\n",
    "print('center_crop :', center_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
