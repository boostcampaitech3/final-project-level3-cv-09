{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import tqdm\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import videotransforms\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pytorch_i3d import InceptionI3d\n",
    "\n",
    "from charades_dataset_full import Charades as Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([videotransforms.CenterCrop(224)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "split = '/opt/ml/input/data/test.json'\n",
    "root = '/opt/ml/input/data'\n",
    "mode = 'rgb'\n",
    "batch_size = 1\n",
    "save_dir = '/opt/ml/input/data'\n",
    "load_model = '/opt/ml/input/code/pytorch-i3d/models/rgb_charades.pt'\n",
    "\n",
    "dataset = Dataset(split, 'training', root, mode, test_transforms, num=-1, save_dir=save_dir)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "val_dataset = Dataset(split, 'testing', root, mode, test_transforms, num=-1, save_dir=save_dir)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=False)    \n",
    "\n",
    "dataloaders = {'train': dataloader, 'val': val_dataloader}\n",
    "datasets = {'train': dataset, 'val': val_dataset}\n",
    "\n",
    "# setup the model\n",
    "if mode == 'flow':\n",
    "    i3d = InceptionI3d(400, in_channels=2)\n",
    "else:\n",
    "    i3d = InceptionI3d(400, in_channels=3)\n",
    "i3d.replace_logits(157)\n",
    "i3d.load_state_dict(torch.load(load_model))\n",
    "i3d.cuda()\n",
    "\n",
    "# for phase in ['train', 'val']:\n",
    "# try:\n",
    "\n",
    "for phase in ['val']:\n",
    "    i3d.train(False)  # Set model to evaluate mode\n",
    "            \n",
    "    tot_loss = 0.0\n",
    "    tot_loc_loss = 0.0\n",
    "    tot_cls_loss = 0.0\n",
    "                \n",
    "    # Iterate over data.\n",
    "    for data in dataloaders[phase]:\n",
    "        # get the inputs\n",
    "        inputs, labels, name = data\n",
    "    \n",
    "        if os.path.exists(os.path.join(save_dir, name[0]+'.npy')):\n",
    "            continue\n",
    "\n",
    "        b,c,t,h,w = inputs.shape\n",
    "        if t > 1600:\n",
    "            features = []\n",
    "            for start in range(1, t-56, 1600):\n",
    "                end = min(t-1, start+1600+56)\n",
    "                start = max(1, start-48)\n",
    "                # ip = Variable(torch.from_numpy(inputs.numpy()[:,:,start:end]).cuda(), volatile=True)\n",
    "                ip = Variable(torch.from_numpy(inputs.numpy()[:,:,start:end]).cuda())\n",
    "                features.append(i3d.extract_features(ip).squeeze(0).permute(1,2,3,0).data.cuda().numpy())\n",
    "            np.save(os.path.join(save_dir, name[0]), np.concatenate(features, axis=0))\n",
    "        else:\n",
    "            # wrap them in Variable\n",
    "            inputs = Variable(inputs.cuda())\n",
    "            features = i3d.extract_features(inputs)\n",
    "            np.save(os.path.join(save_dir, name[0]), features.squeeze(0).permute(1,2,3,0).data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동영상을 사진으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('/opt/ml/input/data/test_video.mp4')\n",
    "FPS = cap.get(5)\n",
    "frame = cap.get(7)\n",
    "count = 1\n",
    "\n",
    "for i in range(1, int(frame)):\n",
    "    success, img = cap.read()\n",
    "    \n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    if i % int(FPS / 1.5) == 0:\n",
    "        cv2.imwrite(f\"/opt/ml/input/data/test_video/test_video\"+'-'+str(count).zfill(6)+'.jpg', img)\n",
    "        count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "result =np.load('/opt/ml/input/data/test_video.npy')\n",
    "result = result.reshape(-1, 1024)\n",
    "\n",
    "result.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/opt/ml/input/data/new_test.npy', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =np.load('/opt/ml/input/data/new_test.npy')\n",
    "test.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
